AWSTemplateFormatVersion: 2010-09-09
Transform: AWS::Serverless-2016-10-31
Description: "Template to set up Kinesis stream, Lambda functions, S3 bucket, Firehose Stream, DynamoDB table and related IAM roles for AWS Lambda Real-time Stream Processing Reference Architecture."

# Parameters:
#   LambdaS3Bucket:
#     Type: String
#     Default: awslambda-reference-architectures
#     Description: Name of S3 bucket where Lambda function packages are stored.
#   LambdaDataStreamConsumerS3Key:
#     Type : String
#     Default : stream-processing/ddb_eventprocessor.zip
#     Description : Name of S3 key for Zip with Stream Processing DynamoDB Event Processor Lambda function package.
#   LambdaDataStreamConsumerHandler:
#     Type : String
#     Default : ddb_eventprocessor.handler
#     Description : Name of handler for Stream Processing DynamoDB Event Processor Lambda function.
Parameters:
  # https://developer.twitter.com/en/docs/trends/trends-for-location/api-reference/get-trends-place
  # Yahoo! Where on Earth ID (WOEID)
  WhereOnEarthID:
    Description: Yahoo! Where on Earth ID (1=Global)
    Type: String
    Default: 1
  Region:
    Description: Region to configure the KPL producer
    Type: String
    Default: us-east-1

Resources:
  #########################################################################################################
  # Event Stream
  #   - Creates the Amazon Kinesis Stream resources
  #########################################################################################################
  DataStream:
    Type: AWS::Kinesis::Stream
    Properties:
      ShardCount: 1

  #########################################################################################################
  # Event Stream Producer - Python
  #   - Creates a Lambda function in Phython which polls Twitter for new tweets and adds them to
  #     the Amazon Kinesis stream.
  #########################################################################################################
  DataStreamProducerPython:
    Type: AWS::Serverless::Function
    Properties:
      Description: Scrape twitter and put events into Kinesis
      FunctionName: !Sub ${AWS::StackName}-DataStreamProducerPython
      MemorySize: 256
      Role: !GetAtt DataStreamProducerPythonExecutionRole.Arn
      Environment:
        Variables:
          LOG_LEVEL: INFO
          KINESIS_STREAM_NAME: !Ref DataStream
          WOEID: !Ref WhereOnEarthID
      Timeout: 600
      Runtime: python3.7
      CodeUri: src/lambda/producer-python
      Handler: main.lambda_handler
      Events:
        # https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html
        TriggerProducerLambda:
          Type: Schedule
          Properties:
            Schedule: rate(10 minutes)
            Name: !Sub ${AWS::StackName}-DataStreamProducerPython-Trigger
            Description: Trigger function every 10 minutes
            Enabled: True
    DependsOn: DataStream

  DataStreamProducerPythonExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${AWS::StackName}-DataStreamProducerPythonExecutionRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: !Sub ${AWS::StackName}-DataStreamProducerPythonExecutionPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - kinesis:PutRecord
                Resource: !GetAtt DataStream.Arn
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/AmazonSSMReadOnlyAccess

  #########################################################################################################
  # Event Stream Producer - Java
  #   - Creates a Lambda function in Java which polls Twitter for new tweets and adds them to
  #     the Amazon Kinesis stream.
  #########################################################################################################
  DataStreamProducerJava:
    Type: AWS::Serverless::Function
    Properties:
      Description: Scrape twitter and put events into Kinesis
      FunctionName: !Sub ${AWS::StackName}-DataStreamProducerJava
      # To reserve appropriate metaspace (10% of allocation) for lambda
      # execution, set this to 256
      MemorySize: 256
      Role: !GetAtt DataStreamProducerJavaExecutionRole.Arn
      Environment:
        Variables:
          LOG_LEVEL: INFO
          KINESIS_STREAM_NAME: !Ref DataStream
          WOEID: !Ref WhereOnEarthID
          REGION: !Ref Region
      Timeout: 600
      Runtime: java8
      # If this does not exist, run `mvn package` in the KPLProducer directory
      CodeUri: src/lambda/producer-java-kpl/KPLProducer
      Handler: kplproducer.KPLProducer::handleRequest
      Events:
        # https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html
        TriggerProducerLambda:
          Type: Schedule
          Properties:
            Schedule: rate(10 minutes)
            Name: !Sub ${AWS::StackName}-DataStreamProducerJava-Trigger
            Description: Trigger function every 10 minutes
            Enabled: True
    DependsOn: DataStream

  DataStreamProducerJavaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${AWS::StackName}-DataStreamProducerJavaExecutionRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: !Sub ${AWS::StackName}-DataStreamProducerJavaExecutionPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - kinesis:PutRecord
                  - kinesis:DescribeStream
                  - kinesis:PutRecords
                Resource: !GetAtt DataStream.Arn
              - Effect: Allow
                Action:
                  - cloudwatch:PutMetricData
                Resource:
                  - "*"
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/AmazonSSMReadOnlyAccess

  #########################################################################################################
  # Firehose S3 Bucket
  # - This bucket will hold all of the firehose transformed records
  #########################################################################################################
  FirehoseS3Bucket:
    Type: AWS::S3::Bucket

  #########################################################################################################
  # Firehose Lambda Transformer
  # - This lambda transforms the stream records before firehose writes them to s3
  #########################################################################################################
  FirehoseTransformLambda:
    Type: AWS::Serverless::Function
    Properties:
      Description: Transform raw Twitter Statuses to condensed records
      FunctionName: !Sub ${AWS::StackName}-FirehoseTransformer
      MemorySize: 128
      Role: !GetAtt FirehoseTransformExecutionRole.Arn
      Timeout: 60
      Runtime: python3.7
      CodeUri: src/lambda/firehose-transformer/fh-transformer
      Handler: main.lambda_handler

  FirehoseTransformExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${AWS::StackName}-FirehoseTransformExecutionRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole

  #########################################################################################################
  # Firehose Delivery Stream
  # - This firehose delivery stream will hook into the lambda firehose transformer to transform
  #   and drop records into the FirehoseS3Bucket
  #########################################################################################################
  FirehoseDeliveryStream:
    Type: AWS::KinesisFirehose::DeliveryStream
    DependsOn:
      - DataStream
      - FirehoseDeliveryPolicy
      - FirehoseS3Bucket
      - FirehoseS3Role
    Properties:
      DeliveryStreamType: KinesisStreamAsSource
      KinesisStreamSourceConfiguration:
        KinesisStreamARN: !GetAtt DataStream.Arn
        RoleARN: !GetAtt FirehoseS3Role.Arn
      ExtendedS3DestinationConfiguration:
        BucketARN: !GetAtt FirehoseS3Bucket.Arn
        BufferingHints:
          IntervalInSeconds: 60
          SizeInMBs: 5
        CompressionFormat: "UNCOMPRESSED"
        Prefix: records/
        ErrorOutputPrefix: errors/
        RoleARN: !GetAtt FirehoseS3Role.Arn
        ProcessingConfiguration:
          Enabled: True
          Processors:
            - Type: Lambda
              Parameters:
                - ParameterName: LambdaArn
                  ParameterValue: !GetAtt FirehoseTransformLambda.Arn
                - ParameterName: BufferSizeInMBs
                  ParameterValue: 3
                - ParameterName: BufferIntervalInSeconds
                  ParameterValue: 60

  FirehoseS3Role:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Sid: ""
            Effect: Allow
            Principal:
              Service: firehose.amazonaws.com
            Action: sts:AssumeRole

  FirehoseDeliveryPolicy:
    Type: AWS::IAM::Policy
    DependsOn:
      - DataStream
    Properties:
      PolicyName: FirehosePolicy
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - s3:AbortMultipartUpload
              - s3:GetBucketLocation
              - s3:GetObject
              - s3:ListBucket
              - s3:ListBucketMultipartUploads
              - s3:PutObject
            Resource:
              - !Join
                - ""
                - - "arn:aws:s3:::"
                  - !Ref FirehoseS3Bucket
              - !Join
                - ""
                - - "arn:aws:s3:::"
                  - !Ref FirehoseS3Bucket
                  - "*"
          - Effect: Allow
            Action:
              - lambda:InvokeFunction
              - lambda:GetFunctionConfiguration
            Resource: !GetAtt FirehoseTransformLambda.Arn
          - Effect: Allow
            Action:
              - kinesis:DescribeStream
              - kinesis:GetShardIterator
              - kinesis:GetRecords
            Resource:
              - !GetAtt DataStream.Arn
          - Effect: Allow
            Action:
              - logs:PutLogEvents
            Resource:
              - !Join
                - ""
                - - "arn:aws:logs:"
                  - !Ref Region
                  - ":"
                  - !Ref "AWS::AccountId"
                  - ":log-group:/aws/kinesisfirehose/"
                  - !Ref DataStream
                  - ":log-stream:*"
      Roles:
        - !Ref FirehoseS3Role

  #########################################################################################################
  # Event Data Table
  #   - Creates a DyanmoDB table where the streaming data will be persisted.
  #   - The table will use On-Demand pricing and have TTL enabled.
  #   - The TTL variable will prevent unexpected storage costs by removing stale items after 1 day
  #     (per DataStreamConsumer Lambda configuraiton)
  #########################################################################################################
  EventDataTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Sub ${AWS::StackName}-EventData
      AttributeDefinitions:
        - AttributeName: Username
          AttributeType: S
        - AttributeName: Id
          AttributeType: S
      KeySchema:
        - AttributeName: Username
          KeyType: HASH
        - AttributeName: Id
          KeyType: RANGE
      BillingMode: PAY_PER_REQUEST
      TimeToLiveSpecification:
        AttributeName: ExpirationTime
        Enabled: true

  #########################################################################################################
  # Event Stream Consumer
  #   - Creates a Lambda function in Node.js which reads from the Kinesis Stream in batches of 25 items
  #     and persists the stream records into a DynamoDB table.
  #########################################################################################################
  DataStreamConsumer:
    Type: AWS::Serverless::Function
    Properties:
      Description: Stream Processing DDB Event Processor
      FunctionName: !Sub ${AWS::StackName}-DataStreamConsumer
      Role: !GetAtt DataStreamConsumerExecutionRole.Arn
      MemorySize: 128
      Timeout: 20
      Environment:
        Variables:
          DDB_TABLE: !Ref EventDataTable
          DDB_TTL_DAYS: 1
      Runtime: nodejs10.x
      CodeUri:
        src/lambda/consumer
        # Bucket: !Ref LambdaS3Bucket
        # Key: !Ref LambdaDataStreamConsumerS3Key
      Handler: ddb_eventprocessor.handler
      # Handler: !Ref LambdaDataStreamConsumerHandler
      Events:
        Stream:
          Type: Kinesis
          Properties:
            Stream: !GetAtt DataStream.Arn
            StartingPosition: TRIM_HORIZON
            BatchSize: 25

  DataStreamConsumerExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${AWS::StackName}-DataStreamConsumerExecutionRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: !Sub ${AWS::StackName}-DataStreamConsumerExecutionPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - dynamodb:BatchWriteItem
                Resource: !GetAtt EventDataTable.Arn
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaKinesisExecutionRole
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole

  #########################################################################################################
  # Event Stream Consumer
  #   - Creates a Lambda function in Node.js which reads from the Kinesis Stream in batches of 25 items
  #     and persists the stream records into a DynamoDB table.
  #########################################################################################################
  Kickoff:
    Type: Custom::Kickoff
    Properties:
      ServiceToken: !GetAtt KickoffFunction.Arn
      Region: !Sub Region
      ProducerJavaArn: !GetAtt DataStreamProducerJava.Arn
      ProducerPythonArn: !GetAtt DataStreamProducerPython.Arn
    DependsOn:
      - DataStreamProducerJava
      - DataStreamProducerPython

  KickoffFunction:
    Type: AWS::Serverless::Function
    Properties:
      Description: Stream Processing DDB Event Processor
      FunctionName: !Sub ${AWS::StackName}-KickoffFunction
      CodeUri: src/lambda/kickoff-function
      Handler: kickoff.handler
      Role: !GetAtt KickoffFunctionExecutionRole.Arn
      Runtime: nodejs10.x
      MemorySize: 128
      Timeout: 30
    DependsOn: KickoffFunctionExecutionRole

  KickoffFunctionExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${AWS::StackName}-KickoffFunctionExecutionRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/service-role/AWSLambdaRole

  #########################################################################################################
  # Monitor Kinesis Stream 
  # https://docs.aws.amazon.com/streams/latest/dev/monitoring-with-cloudwatch.html#kinesis-metric-use
  #   - ReadProvisionedThroughputExceeded
  #   - WriteProvisionedThroughputExceeded	
  #   - GetRecords.IteratorAgeMilliseconds
  #########################################################################################################
  SNSTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Data Stream Monitoring

  MonitorIteratorAge:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref SNSTopic
      AlarmDescription: Monitor Data Stream Iterator Age
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: StreamName
          Value: !GetAtt DataStream.Arn
      EvaluationPeriods: 4
      DatapointsToAlarm: 3
      MetricName: GetRecords.IteratorAgeMilliseconds
      Namespace: AWS/Kinesis
      Period: 300
      Statistic: Maximum
      Threshold: 6000000
      TreatMissingData: missing

  MonitorReadThroughput:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref SNSTopic
      AlarmDescription: Monitor Data Stream Read Provisioned Throughput 
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: StreamName
          Value: !GetAtt DataStream.Arn
      EvaluationPeriods: 4
      DatapointsToAlarm: 3
      MetricName: ReadProvisionedThroughputExceeded
      Namespace: AWS/Kinesis
      Period: 300
      Statistic: Average
      Threshold: 10
      TreatMissingData: missing

  MonitorWriteThroughput:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref SNSTopic
      AlarmDescription: Monitor Data Stream Write Provisioned Throughput 
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: StreamName
          Value: !GetAtt DataStream.Arn
      EvaluationPeriods: 4
      DatapointsToAlarm: 3
      MetricName: WriteProvisionedThroughputExceeded
      Namespace: AWS/Kinesis
      Period: 300
      Statistic: Average
      Threshold: 10
      TreatMissingData: missing

#########################################################################################################
# Stack Outputs
#########################################################################################################
Outputs:
  Region:
    Value: !Ref AWS::Region
  DataStreamName:
    Value: !Ref DataStream
    Description: The Amazon Kinesis stream name.
  DataStreamArn:
    Value: !GetAtt DataStream.Arn
    Description: The Amazon Kinesis stream ARN.
  EventDataTableName:
    Value: !Ref EventDataTable
  EventDataTableArn:
    Value: !GetAtt EventDataTable.Arn
  FirehoseS3BucketArn:
    Value: !GetAtt FirehoseS3Bucket.Arn
    Description: The Firehose S3 Bucket ARN.
